{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Time domain data into lower dimensions\n",
    "In this section, we will use UMAP (Uniform Manifold Approximation and Projection) to reduce the dimensionality of our time domain data from 1024 points down to just 2. This reduction allows us to visualize the structure of our high dimensional data in a 2D plot.\n",
    "\n",
    "But why would we want to do this?\n",
    "\n",
    "Even though each sample contains 1024 time domain values, it’s difficult to build an intuition about the data or spot patterns when we’re working in such high dimensional space. By projecting the data into two dimensions while preserving as much of its underlying structure as possible, we can:\n",
    "\t•\tExplore the data visually: Clusters in the 2D plot might correspond to different physical properties of the samples (e.g., number of layers in a material, material type, etc.).\n",
    "\t•\tGain insights into separability: If we see well-defined clusters, that suggests the data contains meaningful differences that could be exploited by a machine learning model.\n",
    "\t•\tDetect outliers: Points that lie far from any cluster may represent unusual or erroneous data.\n",
    "\n",
    "UMAP is particularly well suited for this kind of task because it preserves both the local and global structure of the data better than older methods like PCA or t-SNE, especially when the data lies on a nonlinear manifold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The supporting data is not uploaded in this repository. Similar datasets can be generated with Data_gen_efficient.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'INSERT-PATH-TO-DATA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset with weights_only=False\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT-PATH-TO-DATA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extract components\u001b[39;00m\n\u001b[1;32m      5\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthetic_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mphys/lib/python3.11/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mphys/lib/python3.11/site-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mphys/lib/python3.11/site-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'INSERT-PATH-TO-DATA'"
     ]
    }
   ],
   "source": [
    "# Load the dataset with weights_only=False\n",
    "data = torch.load(\"INSERT-PATH-TO-DATA\", weights_only=False)\n",
    "\n",
    "# Extract components\n",
    "synthetic_data = data[\"synthetic_data\"]\n",
    "material_params = data[\"material_params\"]\n",
    "num_layers = data[\"num_layers\"]\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Number of samples: {len(synthetic_data)}\")\n",
    "print(f\"Shape of synthetic_data: {synthetic_data.shape}\")\n",
    "print(f\"Shape of num_layers: {num_layers.shape}\")\n",
    "print(f\"Example number of layers: {num_layers[:10]}\")\n",
    "\n",
    "num_classes = int(max(num_layers)) # class labels start at 1 not 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy for UMAP\n",
    "X = synthetic_data.numpy()\n",
    "y = num_layers.numpy()\n",
    "\n",
    "# Run UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP projection\n",
    "plt.figure(figsize=(9, 8))\n",
    "palette = sns.color_palette(\"deep\", num_classes)\n",
    "\n",
    "# Labels start at 1, adjust for color mapping\n",
    "sns.scatterplot(x=X_umap[:, 0], y=X_umap[:, 1], hue=y, palette=palette, legend='full', s=10)\n",
    "plt.title(\"UMAP Projection of Synthetic Time-Domain Data\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.legend(title=\"Number of Layers\", loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: n (real part of first layer)\n",
    "sc1 = axs[0].scatter(X_umap[:, 0], X_umap[:, 1], c=n_real, cmap='viridis', s=5)\n",
    "axs[0].set_title(\"UMAP Projection Colored by Refractive Index (n₁)\")\n",
    "axs[0].set_xlabel(\"UMAP Dimension 1\")\n",
    "axs[0].set_ylabel(\"UMAP Dimension 2\")\n",
    "plt.colorbar(sc1, ax=axs[0], label=\"Re(n₁)\")\n",
    "\n",
    "# Right: total thickness\n",
    "sc2 = axs[1].scatter(X_umap[:, 0], X_umap[:, 1], c=total_thickness, cmap='plasma', s=5)\n",
    "axs[1].set_title(\"UMAP Projection Colored by Total Thickness\")\n",
    "axs[1].set_xlabel(\"UMAP Dimension 1\")\n",
    "axs[1].set_ylabel(\"UMAP Dimension 2\")\n",
    "plt.colorbar(sc2, ax=axs[1], label=\"Thickness (m)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract total thickness per sample\n",
    "total_thicknesses = []\n",
    "for sample in material_params:\n",
    "    total_thickness = sum(D.real for (_, D) in sample)\n",
    "    total_thicknesses.append(total_thickness)\n",
    "\n",
    "total_thicknesses = np.array(total_thicknesses).reshape(-1, 1)  # shape: (N, 1)\n",
    "\n",
    "# Step 2: Prepare the pulse data\n",
    "X_pulses = synthetic_data.numpy()  # shape: (N, 1024)\n",
    "y = num_layers.numpy()             # class labels (1 to 5)\n",
    "\n",
    "# Step 3: Concatenate pulses with total thickness\n",
    "# Normalize both parts first\n",
    "scaler_pulse = StandardScaler()\n",
    "scaler_thick = StandardScaler()\n",
    "\n",
    "X_pulses_scaled = scaler_pulse.fit_transform(X_pulses)\n",
    "thickness_scaled = scaler_thick.fit_transform(total_thicknesses)\n",
    "\n",
    "X_augmented = np.hstack([X_pulses_scaled, thickness_scaled])  # shape: (N, 1025)\n",
    "\n",
    "# Step 4: Run UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X_augmented)\n",
    "\n",
    "# Step 5: Plot\n",
    "plt.figure(figsize=(9, 8))\n",
    "palette = sns.color_palette(\"deep\", np.max(y))  # handles labels 1 to 5\n",
    "\n",
    "sns.scatterplot(x=X_umap[:, 0], y=X_umap[:, 1], hue=y, palette=palette, legend='full', s=10)\n",
    "plt.title(\"UMAP Projection of Time-Domain Pulses + Total Thickness\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.legend(title=\"Number of Layers\", loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
