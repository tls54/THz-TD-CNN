
import torch


## Computer devide detection function
def identify_device():
    device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")
    print(f"Using device: {device}")
    return device


## Data loader handler: Loads pt files generated by Multi-processing.py for classifier and auto-encoder architectures


import torch
from torch.utils.data import DataLoader, TensorDataset

def load_thz_dataset(
    path="Synthetic_data_60k.pt",
    model_type="classifier",
    batch_size=1024,
    shuffle=True
):
    """
    Load the THz synthetic dataset and return a DataLoader.

    Args:
        path (str): Path to the .pt file.
        model_type (str): One of ['classifier', 'autoencoder', 'hybrid'].
        batch_size (int): Batch size for DataLoader.
        shuffle (bool): Whether to shuffle the dataset.

    Returns:
        data_loader (DataLoader): Batched data.
        num_classes (int or None): Number of classes (only for classifier/hybrid).
        input_dim (int): Length of the 1D time-domain signal.
    """
    assert model_type in ["classifier", "autoencoder", "hybrid"], "Invalid model_type."

    data = torch.load(path, weights_only=False)

    synthetic_data = data["synthetic_data"]  # [N, 1024]
    num_layers = data["num_layers"]          # [N] (class labels starting from 1)

    input_dim = synthetic_data.shape[1]      # Should be 1024

    # CNN/Hybrid: Need labels (adjusted to 0-based)
    if model_type in ["classifier", "hybrid"]:
        num_layers_adjusted = num_layers - 1
        num_classes = int(num_layers_adjusted.max().item()) + 1
        print(f"Loaded labels: {num_classes} classes (0-based)")
    else:
        num_classes = None  # Not needed for autoencoder

    # Unsqueeze for Conv1D input [B, 1, 1024]
    synthetic_data = synthetic_data.unsqueeze(1)

    # Create dataset
    if model_type == "autoencoder":
        dataset = TensorDataset(synthetic_data)
    else:
        dataset = TensorDataset(synthetic_data, num_layers_adjusted)

    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)

    print(f"Dataset loaded: {len(dataset)} samples")
    print(f"Input shape: {synthetic_data.shape}")
    return data_loader, num_classes, input_dim